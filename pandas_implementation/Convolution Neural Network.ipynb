{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import tqdm\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create path variables to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"D:/Projects/diabetic_retinopathy_IDRD/Disease Grading/\"\n",
    "train_images = os.path.join(DATADIR, \"Images/Training Set\")\n",
    "train_labels = os.path.join(DATADIR, \"Labels/Training_Labels.csv\")\n",
    "\n",
    "test_images = os.path.join(DATADIR, \"Images/Testing Set\")\n",
    "test_labels = os.path.join(DATADIR, \"Labels/Testing_Labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = glob.glob(os.path.join(train_images, '*.jpg'))\n",
    "train_image_path_dict = {os.path.splitext(os.path.basename(x))[0]:x for x in train_image_path}\n",
    "\n",
    "test_image_path = glob.glob(os.path.join(test_images, '*.jpg'))\n",
    "test_image_path_dict = {os.path.splitext(os.path.basename(x))[0]:x for x in test_image_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Image_name  Retinopathy_grade  \\\n",
      "0  IDRiD_001                  3   \n",
      "1  IDRiD_002                  3   \n",
      "2  IDRiD_003                  2   \n",
      "3  IDRiD_004                  3   \n",
      "4  IDRiD_005                  4   \n",
      "\n",
      "                                    train_image_path  \n",
      "0  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "1  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "2  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "3  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "4  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "  Image_name  Retinopathy_grade  \\\n",
      "0  IDRiD_001                  4   \n",
      "1  IDRiD_002                  4   \n",
      "2  IDRiD_003                  4   \n",
      "3  IDRiD_004                  4   \n",
      "4  IDRiD_005                  4   \n",
      "\n",
      "                                     test_image_path  \n",
      "0  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "1  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "2  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "3  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n",
      "4  D:/Projects/diabetic_retinopathy_IDRD/Disease ...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(train_labels)\n",
    "del df['Risk of macular edema']\n",
    "df['train_image_path'] = df['Image_name'].map(train_image_path_dict.get)\n",
    "print(df.head())\n",
    "\n",
    "df2 = pd.read_csv(test_labels)\n",
    "del df2['Risk of macular edema']\n",
    "df2['test_image_path'] = df['Image_name'].map(train_image_path_dict.get)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "def create_dataset():\n",
    "    dataset = []\n",
    "    for index in df.index:\n",
    "        image = cv2.resize(cv2.imread(df.train_image_path[index], cv2.IMREAD_GRAYSCALE), IMAGE_SIZE)\n",
    "        label = df.Retinopathy_grade[index]\n",
    "        dataset.append([image, label])\n",
    "    return dataset\n",
    "\n",
    "def create_test_dataset():\n",
    "    dataset = []\n",
    "    for index in df2.index:\n",
    "        image = cv2.resize(cv2.imread(df2.test_image_path[index], cv2.IMREAD_GRAYSCALE), IMAGE_SIZE)\n",
    "        label = df2.Retinopathy_grade[index]\n",
    "        dataset.append([image, label])\n",
    "    return dataset\n",
    "\n",
    "def create_sample_dataset(X):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for features, label in X:\n",
    "            x.append(features)\n",
    "            y.append(label)\n",
    "\n",
    "    x = np.array(x).reshape(-1, IMAGE_SIZE[0], IMAGE_SIZE[1],1)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataset\n",
    "image_dataset = create_dataset()\n",
    "\n",
    "#Shuffle dataset randomnly\n",
    "random.shuffle(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = create_sample_dataset(image_dataset)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataset\n",
    "test_dataset = create_test_dataset()\n",
    "\n",
    "#Shuffle dataset randomnly\n",
    "random.shuffle(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx, ty = create_sample_dataset(test_dataset)\n",
    "print(tx.shape, ty.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(x, y, epochs=75, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x, y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate loaded model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(tx, ty, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
